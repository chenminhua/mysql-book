{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple apple PROPN NNP nsubj Xxxxx True False\n",
      "is be VERB VBZ aux xx True True\n",
      "looking look VERB VBG ROOT xxxx True False\n",
      "at at ADP IN prep xx True True\n",
      "buying buy VERB VBG pcomp xxxx True False\n",
      "U.K. u.k. PROPN NNP compound X.X. False False\n",
      "startup startup NOUN NN dobj xxxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "$ $ SYM $ quantmod $ False False\n",
      "1 1 NUM CD compound d False False\n",
      "billion billion NUM CD pobj xxxx True False\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(u'Apple is looking at buying U.K. startup for $1 billion')\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple 0 5 ORG\n",
      "U.K. 27 31 GPE\n",
      "$1 billion 44 54 MONEY\n"
     ]
    }
   ],
   "source": [
    "# A named entity is a “real-world object” that’s assigned a name – \n",
    "# for example, a person, a country, a product or a book title. \n",
    "# spaCy can recognizevarious types of named entities in a document, by asking the model for a prediction. \n",
    "# Because models are statistical and strongly depend on the examples they were trained on, \n",
    "# this doesn’t always work perfectly and might need some tuning later, depending on your use case.\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog True 7.0336733 False\n",
      "cat True 6.6808186 False\n",
      "banana True 6.700014 False\n",
      "afskfsd False 0.0 True\n"
     ]
    }
   ],
   "source": [
    "## python -m spacy download en_core_web_lg  很大。。。\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "tokens = nlp(u'dog cat banana afskfsd')\n",
    "\n",
    "for token in tokens:\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog dog 1.0\n",
      "dog cat 0.80168545\n",
      "dog banana 0.24327643\n",
      "cat dog 0.80168545\n",
      "cat cat 1.0\n",
      "cat banana 0.28154364\n",
      "banana dog 0.24327643\n",
      "banana cat 0.28154364\n",
      "banana banana 1.0\n"
     ]
    }
   ],
   "source": [
    "# 根据word vector计算similarity\n",
    "tokens = nlp(u'dog cat banana')\n",
    "\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipelines\n",
    "\n",
    "text -> tokenizer -> tagger -> parser -> ner -> ... -> Doc\n",
    "\n",
    "tokenizer 把text分割成token\n",
    "\n",
    "tagger assign part-of-speech tags (POS tagging / POST)\n",
    "\n",
    "parser   assign dependency labels\n",
    "\n",
    "ner      detect and label named entities\n",
    "\n",
    "textcat  文本分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[93m    Serving on port 5000...\u001b[0m\n",
      "    Using the 'dep' visualizer\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [25/Apr/2019 12:21:49] \"GET / HTTP/1.1\" 200 3057\n",
      "127.0.0.1 - - [25/Apr/2019 12:21:49] \"GET /favicon.ico HTTP/1.1\" 200 3057\n"
     ]
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "doc = nlp(u\"This is a sentence.\")\n",
    "displacy.serve(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
