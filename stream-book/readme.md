一般来说，「流」指随着时间推移而持续可用的数据。比如 unix 的 stdio，文件系统 api（比如 java 的 fileInputStream），TCP 连接等等。我们可以把「事件流」看成**一种无界的，持续增量处理的数据管理方式**。

在流处理中，记录通常被称为事件（一个小的，独立的，不可变的，包含发生时间和事件细节的对象）。每个时间包含一个时间戳（墙上时间）。

### 消息系统

如果生产者发送数据比消费者快，怎么办？通常有三种选择：丢弃消息；缓存消息；back pressure。TCP 使用背压：先设立一个固定大小的缓存，如果缓存消费太慢，就调整发送方滑动窗口，进行流控。

如果节点崩溃或离线，是否会丢消息？持久化需要写入磁盘，并结合复制方案，而这些都是成本，如果能接受丢消息，那可以换来更高的吞吐和更低的延迟。

消息系统的一种方案是生产者消费者直接通信。比如 UDP 组播广泛应用在股票市场等低延迟场景；zeroMQ 也是使用无代理的消息库；或者由生产者直接通过 rpc 调用消费者。

另一种方案是使用消息代理。**消息代理是一种针对消息流优化的数据库**。消息代理有时会带来很明显的延迟。

### CDC（变更数据捕获）

大多数数据库复制日志的问题在于，它们被认为是数据库的内部实现，而不是公开的 API，客户端应该通过其数据模型和查询语言来查询数据库而不是分析复制日志并从中提起数据。

但是如今，CDC 越来越引起人们的重视。CDC 记录了写入数据的所有变更，并以可复制到其他系统的形式来提取数据。如果写入时立即将更改作为流来发布，CDC 就更有趣了。目前越来越多的数据库开始之初将 CDC 流作为标准接口。

CDC 通常是异步的，这种方式的优势是记录数据库的写入不受影响，当然也会带来复制滞后的问题。

### 事件与命令

事件溯源的哲学是小心区分事件和命令。用户请求到达时，最初是一个命令，当命令被接收并执行成功后，它将变成一个不可变的事件。

### 不变事件的优势

数据库中的不变性是个古老的想法，会计师在财务报表中一直利用着不变性。交易发生时，记录仅仅是追加，如果发生错误，也不会更改记录，而是追加一笔交易。不可变的事件还会捕获更多信息，不仅仅是当前的状态。

### 从事件日志派生多个视图

从事件日志到数据库有一个明确的转换步骤，可以更加容易地随时间来演进应用程序：如果想引入一个新的方式呈现数据，可以用事件日志来构建一个单独针对新功能的读取优化视图，并与现有的系统一起运行，而不需要修改它们。同时运行旧系统和新系统通常比在现有系统执行 migration 来得更容易。

如果不必担心如何去查询和访问数据，那么数据存储将变得非常容易。模式设计、索引和存储引擎的许多复杂设计很多都是源于希望支持多种查询和访问模式。而如果将数据的写入与读取分离，并允许多个不同的读取视图，可以得到更大的灵活性。这就是 CQRS。

数据库与 schema 设计的传统方式往往基于数据查询必须与写入类型相同的谬误。如果可以将写优化的事件日志转换为读优化的应用程序状态，有关规范化和非规范化的争论就会变得无关紧要，在读优化的视图中对数据进行反规范化处理是完全合理的。

### 流处理

有了流可以用来干嘛？

- 将事件中的数据写入数据库、缓存、搜索引擎或类似的存储系统，然后被其他客户端查询。
- 可以通过某种方式将事件推送给用户，例如电子邮件或实时仪表，这时候流的消费者是最终用户。
- 可以从流产出流，形成流水线，最终输出。

流与批量作业的一个区别是，流不会结束。这导致很多含义：排序对无界数据没有意义。流处理不能简单的崩溃后重头开始。

流处理长期被使用于监控目的，即希望在发生某些特定事件时收到警报。例如：

- 信用卡欺诈检测系统。
- 交易系统需要检查金融市场的价格变化，并根据指定的规则进行交易。
- 制造系统需要监控工厂中机器的状态，在出现故障时快速识别。

#### 复杂事件处理

复杂事件处理（Complex Event Processing, CEP）是为分析事件流而发展的一种方法，尤其适用于需要搜索特定的事件模式。CEP 允许指定规则，从而可以在流中搜索特定模式的事件。

CEP 系统通常使用类似 SQL 的高级声明式查询语言或图形界面来描述应该检测到的事件模式，将查询语句提交给处理引擎，当处理引擎匹配到事件时，将报告给上游系统具体细节。

在这些系统中，查询和数据间的关系与普通数据库恰好相反。通常数据库会持久化数据，并将查询视为暂时的。而对 CEP 来说，查询是长期存在的，而来自输入流的事件不断流过 CEP 来匹配事件模式。

### 流分析

使用流处理的另一个领域是流分析。CEP 和流分析之间的界限有些模糊，但是一般来说，分析往往不太关心找到特定事件序列，而更关心大量事件的累计效果和统计指标。比如：

- 测量某种类型事件的速率
- 计算一段时间内某个值的滚动平均值
- 将当前的统计数据与以前的时间间隔进行比较

### 在流上搜索

除了 CEP，有时还需要基于一些复杂条件来搜索单个事件。比如媒体监控服务订阅来自媒体机构的新闻文章或者公告，并支持搜索关于公司、产品或感兴趣主题相关的新闻。这是通过预先设定一个搜索查询来完成的，然后不断将新闻流与这个查询匹配。

在一些网站上也有类似的功能：例如房地产网站的用户需要当市场上出现符合其搜索条件的新房产时被及时通知。es 的过滤器功能是实现这种流式搜索的一种方式。

传统的搜索引擎首先索引文档，然后在索引上运行查询。而搜索流则是先将查询保存下来，然后让所有的文档流过去。

### 流式 join

##### 流与流 join

假设某网站支持搜索功能，并想要检测网址搜索的最新趋势。每次有人输入搜索查询时，都会记录包含查询和返回结果的事件。每次有人单击搜索结果，都会记录一个单击事件。为了计算搜索结果中每个网址的单击率，需要将搜索结果和单击操作组合在一起，这些事件通过具有相同会话 id 进行 join。广告系统也需要类似的分析。

搜索和单击之间的时间间隔是不确定的，甚至由于网络延迟的存在，单击事件完全可能在搜索事件之前到达。我们需要定义合适的 join 窗口，例如 1 个小时。

为了实现这种流和流的 join，流处理需要维护状态。

##### 流与表 join

##### 表和表 join

# 流系统

过去，streaming system 通常被用于处理一些低延迟，不精确的场景，而 batch system 则用于提供最终的正确结果，这种将 streaming system 和 batch system 结合的方案被称为 lambda 架构。但是这种方案实现困难，你需要维护两个不同版本的 pipeline，并且在最后将两个 pipeline 进行 merge。

Confluent 联合创始人兼 CEO，同时也是 kafka 的最初作者 Jay Kreps 写过一篇文章 diss lambda 架构: https://www.oreilly.com/radar/questioning-the-lambda-architecture/

Jay 通过使用 kafka 这种 replayable system 作为 streaming interconnect 来解决 lambda 架构带来的重复性，并以此提出了 kappa 架构（running a single pipeline）。

而我认为一个好的 streaming system 实际上可以通过 batch system 的超集。可以参考 apache flink。

batch system 和 streaming system 之间的 trade-of 其实就是 latency 和 efficiency 之间的差异。我们希望能在一个 unified model 下面同时提供 batch 和 streaming 的 runner。

**correctness**: streaming system need a method for checkpointing persistent state over time.[Why local state is a fundamental primitive in stream processing](https://www.oreilly.com/ideas/why-local-state-is-a-fundamental-primitive-in-stream-processing)

**tools for reasoning about time** 也很重要。

### event time versus processing time

为了处理无界的无限数据，通常会采用 windowing incoming data 的方法。将数据集分割成有限集合段。

如果你在乎 correctness 并且想基于 event time 来分析数据，你就不能用 processing time 来划分数据。但是，按照 event time 来划分数据也不太现实，因为你很难知道你是否已经得到了某个 event time 的所有数据。

we should designing tools that allow us to live in the world of uncertainty imposed by these complex datasets. New data will arrive, old data might be retracted or updated.

fixed windows

sessions
