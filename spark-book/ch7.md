# 集群
spark可以在各种各样的集群管理器（yarn, mesos, 还有spark自带的独立集群管理器）上运行

## 运行时架构
主从架构，一个节点（驱动器）负责中央协调，其他节点（执行器）负责具体工作。驱动器节点，集群管理器，以及执行器一起被称为一个spark应用。

## 驱动器节点
驱动器是执行你的程序中的main方法的进程。事实上，当你启动spark shell时，你就启动了一个spark驱动器程序。驱动器程序一旦终止，spark应用也就结束了。

驱动器程序的职责：

  （1）把用户程序转为任务。从上层来看，所有的spark程序都遵循同样的结构：从输入数据创建RDD,在用转化操作派生新的RDD，最后收集结果。spark其实是隐式创建了一个由操作组成的逻辑上的有向无环图。

  （2）为执行器节点调度任务。执行器启动后，会想驱动器注册自己，因此驱动器进程始终对应用中所有的执行器节点都有完整的记录。可以通过localhost:4040查看网页用户界面

## 执行器节点
负责运行组成spark应用的任务，并将结果返回给驱动器进程。

通过自身的块管理器，为用户程序中要求缓存的RDD提供内存存储。

## 集群管理器
spark依赖集群管理器来启动执行器节点，集群管理器是spark中的可插拔式组件。

## 启动一个程序
不论使用哪一种集群管理器，都可以使用spark-submit将应用提交到那种集群管理器上。spark-submit可以连接到相应的集群管理器上，并控制应用所使用的资源数量。


# 使用spark-submit部署应用
```
spark-submit [option] filename [app option]
```

# 独立集群管理器
spark可以运行在各种集群管理器上，并通过集群管理器访问集群中的机器。

  把编译好的spark放到各个机器的同一个目录下

  设置好主节点到其他机器的ssh无密码登录。(ssh私钥放到.ssh/authorized_keys文件里)

  编辑主节点的conf/slaves文件并填上所有工作节点的主机名。

  在主节点上运行sbin/start-all.sh来启动集群

  在主节点上执行bin/stop-all.sh可以停止集群

  spark-submit --master spark://masternode:7077 yourapp 提交应用

# YARN

# Mesos

# Amazon EC2

# 选择合适的集群管理器
从零开始 - 独立集群管理器

要用更丰富的资源调度功能 - yarn和mesos

最好把spark运行在运行HDFS的节点上，这样能快速访问存储。
