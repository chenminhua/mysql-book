# 边车模式 sidecar

- 不在服务中增加控制面上的东西，比如日志、监控、限流、熔断、服务注册、协议适配转换，而是将这些东西都交给边车。
- 边车像是服务的一个 agent，服务所有对外的通信都通过这个 agent。
- sidecar 需要和应用服务有一模一样的生命周期。
- sidecar 模式很适合用在对于老旧系统的升级改造中。（老代码很难改的）
- istio 就是使用了 sidecar 模式。

日志、监控、限流这些需求通常有两种方式来实现。一种是 sdk，lib 的方式集成进服务。一种是 sidecar 的方式。两者的区别在于前者是开发时集成，而后者是运维时集成。前者有利于资源的利用，性能也更好，但是对应用有侵入。后者对应用完全没有侵入，但是延时更长，也增加了管理部署的难度。

# service mesh

https://time.geekbang.org/column/article/5920

# 网关模式

Sidecar, service mesh 都是在不侵入业务的前提下，将业务和控制分离开，但是这两种方案都极大地增加了运维成本。

更为简单的架构模式是，为一组服务提供一个 gateway；甚至也可以粗到为整个集群提供一个接入的 gateway。gateway 和设计模式中的 facade 模式有点像，gateway 封装内部系统的架构并提供对外的 api。gateway 可以提供的功能：

- 请求路由
- 服务注册
- 负载均衡
- 弹力设计 （异步、重试、幂等、流控、熔断）
- 安全设计 （鉴权, session）
- api 聚合 （将多个后端服务请求聚合成一个）
- api 编排 微服务架构下，要走完一个完整的业务流程，需要调用一系列 API，就像工作流一样，这完全可以通过网页来编排这个业务流程。我们可能通过一个 DSL 来定义和编排不同的 API，也可以通过像 AWS Lambda 服务那样的方式来串联不同的 API。

### 对比 sidecar, gateway 和 service mesh 三种模式

- sidecar 适合用于改造已有的服务，可以用于干很多业务透明的活。
- 当 sidecar 越来越多的时候，我们就需要统一管理这些 sidecar，就有了 service mesh。
- 我们把所有业务无关的东西都放在 sidecar 和 controller 中。业务方只需要把服务往网格中一放就好了。
- gateway 简单一点，通过 gateway 封装后端业务，并在其上做很多控制。一般来说 gateway 更容易使用。

### 网关设计重点

- 高性能
- 高可用：集群化，服务化（可以动态修改配置），持续化（能够优雅自动重启）
- 高扩展：网关上或多或少要做一些逻辑的，可扩展性很重要
- 运维方面：要有监控，有 trace 链路跟踪。要统计好每个 api 的吞吐量和返回时间。要有弹力设计。
- 安全方面： 网关鉴权，网关要能检测异常请求。
- 整体架构：不要直接在网关上聚合后端 api, 应该把 api 聚合放在网关后面的某个服务上，也可以使用 plugin 的方式。网关要和后端在一个内网。考虑 bulkhead，比如不同的客户端用不同的网关。

# 配置中心

- 静态配置：操作系统的网络配置等等初始化时候用到的配置，不太会在运行时修改。
- 动态配置：日志级别，降级开关，活动开关等等运行时可以修改的一些配置。

动态配置的管理

- 按环境分：开发环境, 测试环境, staging 环境, prod 环境。
- 按依赖分：自身内部的配置，外部依赖的配置（比如 mysql 的连接配置）
- 按层次分：基础层的配置，平台层的配置，应用层的配置

### 配置中心的模型

**我们把配置分成三层。操作系统层和平台层的配置项得由专门的运维人员或架构师来配置。其中的 value 应该是选项，而不是让用户可以自由输入的，最好是有相关的模板来初始化全套的配置参数。而应用层的配置项，需要有相应的命名规范，最好有像 C++ 那样的名字空间的管理，确保不同应用的配置项不会冲突。**

配置参数如果有外部服务依赖的配置，不要放在配置中心里，而要放在服务发现系统中。这样会减少因不同环境而导致配置不同的差异性（如测试环境和生产环境的不同）。

对于不同运行环境中配置的差异来说，比如在开发环境和测试环境下，日志级别是 Debug 级，对于生产环境则是 Warning 或 Error 级，因为环境的不一样，会导致我们需要不同的配置项的值。这点需要考虑到。

配置需要一个整体的**版本管理**，每次变动都能将版本差异记录下来，最好能和软件的版本号做关联。

有些配置是通过模板来选择的，有的配置需要在不同环境下配置不同值。所以，还需要一个配置管理的工具，可能是命令行的，也可以是 Web 的。用户可以根据不同的机器型号还有不同的环境直接调出后台配置好的相关标准配置的模板。对于一些用户需要自己调整的参数也可以在这个模板上进行调整和配置。然后，用户可以在下面的那个表格中填写好自己的应用要用的参数和各个环境中的值。
这样一来，这个工具就可以非常方便地让开发人员来配置他们自己的软件配置。而我们的配置中心还需要提 API 来让应用获取配置。这个 API 上至少需要有如下参数：服务名，配置的版本号，配置的环境。

### 配置中心的架构

配置录入后，配置中心发出变更通知，控制器来读取最新配置并应用。

为什么不直接 Pub 数据过去，还要订阅方反向拉数据？直接推数据当然可以，但让程序反过来用 API 读配置的好处是，一方面，API 可以校验请求者的权限，另一方面，有时候还是需要调用配置中心的基本 API，比如下载最新的证书之类的。还有就是，服务启动时需要从服务中心拉一份配置下来。

配置变更控制器部署在哪里？是在每个服务器上呢，还是在一个中心的地方？我觉得因为这个事是要变更配置，变更配置又是有很多步骤的，所以这些步骤算是一个事务，建议把这个配置变更的控制放在每一台主机上。

平台层的配置变更，有的参数是在服务启动的命令行上，这个怎么变更呢？ 一般来说，命令行上的参数需要通过 Shell 环境变量做成配置项，然后通过更改系统环境变量，并重启服务达到配置变更。

操作系统的配置变更和平台层的配置变更最好模块化掉，就像云服务中的不同尺寸的主机型号一样。 这样有利于维护和减少配置的复杂性。

应用服务配置更新的标准化。 因为一个公司的应用由不同的团队完成，所以，可能其配置会因为应用的属性不同而不一样。为了便于管理，最好有统一的配置更新。一般来说，有的应用服务的配置是在配置文件中，有的应用服务的配置是通过调用 Admin API 的方式变更，不同的应用系统完全不一样，你似乎完全没有方法做成统一的。这里给几个方案。

可以通过一个开发框架或 SDK 的方式来解决，也就是应用代码找你这个 SDK 来要配置，并通过 observer 模式订阅配置修改的事件，或是直接提供配置变更的 Admin 的 API。这种方式的好处在于在开发期标准化，并可以规范开发；不好的是，耦合语言。

通过一个标准应用运维脚本，让应用方自己来提供应用变更时的脚本动作。这种方式虽然通过运维的方式标准化掉配置变更的接口，就可以通过一个配置控制器来统一操作各个应用变更，但是在这个脚本中各个应用方依然使用着各种不同的方式来变更配置。这种方式的好处是不耦合语言，灵活，但对于标准化的建设可能不利，而且使用或者调用脚本是 Bug 很多的东西，容易出问题。
或是结合上述两种方案，不使用开发阶段的 SDK 方式嵌入到应用服务中，而是为每个应用服务单独做一个 Agent。这个 Agent 对外以 Admin API 的方式服务，后面则适配应用的配置变更手段，如更新配置文件，或者调用应用的 API 等。这种方式在落地方面是很不错的（这其中是另一种设计模式，后面会讲到）。

### 配置中心的设计重点

- 配置中心的设计重点应该放在如何统一和标准化软件的配置项，其还会涉及到软件版本、运行环境、平台、中间件等一系列的配置参数。
- 配置更新的时候是一个事务处理，需要考虑事务的问题，如果变更不能继续，需要回滚到上个版本的配置。配置版本最好和软件版本对应上。
- 配置更新控制器，需要应用服务的配合，比如，配置的 reload，优雅重启，服务的 Admin API，或是通过环境变量。
- 配置更新控制器还担任服务启动的责任，由配置更新控制器来启动服务。controller 会从配置中心拉所有的配置，更新操作系统，设置启动时用的环境变量，并更新服务需要的配置文件 ，然后启动服务。

# 分布式锁

分布式锁的特点：安全性（排他），避免死锁，容错性。
必须保证只有一个客户端可以获得锁，必须保证获得锁的客户端崩溃了之后其他客户端能得到锁，必须保证只要锁服务集群中的大部分节点存活的情况下 client 能进行加锁和解锁操作。

Redis 的分布式锁服务 https://redis.io/topics/distlock，加锁：

```sh
# NX表示只在key不存在才赋值，PX通知redis保存30秒。
SET resource_name my_random_value NX PX 30000
```

my_random_value 必须全局唯一（用于标识加锁的客户端，比如可以用主机 ip+线程 id，这个随机数在释放锁时保证释放锁操作的安全性）。在解锁的时候，必须检查这个 key 对应的 value 是不是客户端传来的值，如果确实是加锁的客户端申请解锁，才能调用 del 命令解锁。

### fence 与 CAS

假设 client-A 拿到了锁，但是它在处理业务的时候被阻塞住了（比如 full gc），阻塞时间太长因而超过了锁过期时间，锁就过期了，这时 client-B 就拿到了锁。这时候 client-A 和 client-B 都认为自己独占着锁。

要解决这个问题，你需要引入 fence（栅栏）技术。一般来说，这就是乐观锁机制，需要一个版本号排它。锁服务需要一个版本号；写数据的时候要带上版本号；数据库服务需要保存数据的版本号。如果使用 ZooKeeper 做锁服务的话，那么可以使用 zxid 或 znode 的版本号来做这个 fence 版本号。

这时候我们完全不需要锁服务了，用数据库里面的版本号不就行了嘛。一般是通过为数据库表增加一个数字类型的 “version” 字段来实现的。当读取数据时，将 version 字段的值一同读出，数据每更新一次，对此 version 值加一。

```sql
UPDATE table_name SET xxx = #{xxx}, version=version+1 where version =#{version};

--还有一种是先把库存数量（stock）查出来，然后在更新的时候，检查一下是否是上次读出来的库存。
SELECT stock FROM tb_product where product_id=#{product_id};
UPDATE tb_product SET stock=stock-#{num} WHERE product_id=#{product_id} AND stock=#{stock};
```

### 分布式锁设计的重点

- 锁需要有超时机制，以避免解锁失败出现死锁。
- 锁服务自动解锁了，导致两个进程都拿到锁的问题，有时候应当考虑使用 CAS，而非锁服务。
- 如果不是更新数据的场景，只是互斥一下不同机器上的线程，这时候像 Redis 这样的分布式锁服务就有意义了。
- 分布式锁服务应该 HA，而且是需要持久化的。可以看一下 Redis 的文档 RedLock 是怎么做到高可用的。
- 要提供非阻塞方式的锁服务。
- 要考虑锁的可重入性。
- Apache 有 Curator 帮我们封装了各种分布式锁的玩法。
