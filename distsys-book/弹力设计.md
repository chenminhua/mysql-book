弹力设计又叫容错设计，主要用于保障系统的可用性。。包括

- 容错能力（服务隔离，异步调用，请求幂等性）
- 可伸缩性 （无状态应用）
- 一致性（事务补偿，重试）
- 应对大流量的能力（熔断，降级）。
- 分布式系统架构的一些设计模式：比如边车模式，service mesh 等等。
- 性能设计方面包括：缓存，CQRS, 索引表，优先级队列，业务分片等。

### 故障原因

- 无计划的：
  -- 系统故障： 主机，操作系统，中间件，数据库，网络，电源以及外围设备。
  -- 数据故障：人员误操作，数据乱了。
  -- 自然灾害，人为破坏，供电问题。
- 有计划的：
  -- 日常任务：备份，容量规划，用户和安全管理，后台批处理应用。
  -- 运维相关：数据库维护，应用维护，中间件维护，操作系统维护，网络维护。
  -- 升级相关：数据库，应用，中间件，操作系统等等

- 网络问题
- 性能问题
- 安全问题
- 运维问题
- 管理问题
- 硬件问题

### 弹力设计总图

- 负载均衡 + 服务健康检查
- 服务发现 + 动态路由 + 服务健康检查
- 自动化运维，k8s 服务调度、伸缩和 fail over

# 补偿事务

ACID：大家在买同一本书的过程中，每个用户的购买请求都需要把库存锁住，等减完库存后，把锁释放出来，后续的人才能进行购买。于是，在 ACID 的玩法下，我们在同一时间不可能有多个用户下单，我们的订单流程需要有排队的情况，这样一来，我们就不可能做出性能比较高的系统来。

BASE：大家都可以同时下单，这时不需要去真正地分配库存，而后台系统异步地处理订单时，发现库存没了，才告诉用户购买失败。亚马逊就是这么玩的，因为要根据用户的地址去不同的仓库查看库存，这个操作非常耗时，只能做成异步的。在亚马逊上买东西，你会收到一封邮件说，系统收到你的订单了，然后过一会儿你会收到你的订单被确认的邮件，这时候才真正分配了库存。

### 业务补偿

在业务需要跨多个系统的时候，尤其是这些系统还不是由一个公司所提供的，我们往往无法做到强一致。比如，在我们的日常生活中，我们经常会遇到这样的情况，就是要找很多方协调很多事，而且要保证我们每一件事都成功，否则整件事就做不到。

比如，要出门旅游， 我们需要干这么几件事。第一，向公司请假，拿到相应的假期；第二，订飞机票或是火车票；第三，订酒店；第四，租车。这四件事中，前三件必需完全成功，我们才能出行，而第四件事只是一个锦上添花的事，但第四件事一旦确定，那么也会成为整个事务的一部分。这些事都是要向不同的组织或系统请求。我们可以并行地做这些事，而如果某个事有变化，其它的事都会跟着出现一些变化。

分布式系统也是一样的，当条件不满足，或是有变化的时候，需要从业务上做相应的整体事务的补偿。

一般来说，业务的事务补偿都是需要一个工作流引擎的。亚马逊是一个超级喜欢工作流引擎的公司，这个工作流引擎把各式各样的服务给串联在一起，并在工作流上做相应的业务补偿，整个过程设计成为最终一致性的。
对于业务补偿来说，首先需要将服务做成幂等性的，如果一个事务失败了或是超时了，我们需要不断地重试，努力地达到最终我们想要的状态。然后，如果我们不能达到这个我们想要的状态，我们需要把整个状态恢复到之前的状态。另外，如果有变化的请求，我们需要启动整个事务的业务更新机制。

所以，一个好的业务补偿机制需要做到下面这几点。

- 要能清楚地描述出要达到什么样的状态，以及如果其中的条件不满足，那么，我们要回退到哪一个状态。
- 当整条业务跑起来的时候，我们可以串行或并行地做这些事。对于旅游订票是可以并行的，但是对于网购流程（下单、支付、送货）是不能并行的。总之，我们的系统需要努力地通过一系列的操作达到一个我们想要的状态。如果达不到，就需要通过补偿机制回滚到之前的状态。这就是所谓的状态拟合。
- 对于已经完成的事务进行整体修改，可以考虑成一个修改事务。

其实，在纯技术的世界里也有这样的事。比如，线上运维系统需要发布一个新的服务或是对一个已有的服务进行水平扩展，我们需要先找到相应的机器，然后初始化环境，再部署上应用，再做相应的健康检查，最后接入流量。这一系列的动作都要完全成功，所以，我们的部署系统就需要管理好整个过程和相关的运行状态。

### 业务补偿的设计重点

- 要努力地把一个业务流程执行完成，这需要流程中所涉及的服务方支持幂等，并且在上游有重试机制。
- 如果执行不下去，需要启动补偿机制，回滚业务流程。

我们需要小心维护和监控整个过程的状态，所以，千万不要把这些状态放到不同的组件中，最好是一个业务流程的控制方来做这个事，也就是一个工作流引擎。这个工作流引擎是需要高可用和稳定的。这就好像旅行代理机构一样，我们把需求告诉它，它会帮我们搞定所有的事。如果有问题，也会帮我们回滚和补偿的。

要明确，业务补偿的业务逻辑是强业务相关的，很难做成通用的。补偿的业务逻辑和流程不一定非得是严格反向操作。有时候可以并行，有时候，可能会更简单。总之，设计业务正向流程的时候，也需要设计业务的反向补偿流程。

下层的业务方最好提供短期的资源预留机制。就像电商中的把货品的库存预先占住等待用户在 15 分钟内支付。如果没有收到用户的支付，则释放库存。然后回滚到之前的下单操作，等待用户重新下单。

# 重试

- 什么情况下需要重试：调用超时、被调用端返回了某种可以重试的错误（如繁忙中、流控中、维护中、资源不足等）。
- 不该重试的场景：业务级的错误（如没有权限），技术上的错误（503，可能是触发了 bug，重试下去没有意义）。
- 重试还需要考虑被调用方是否有幂等的设计。

重试的时间和重试的次数。如果超过重试次数，或是一段时间，那么重试就没有意义了。这个时候，说明这个错误不是一个短暂的错误，那么我们对于新来的请求，就没有必要再进行重试了，这个时候对新的请求直接返回错误就好了。但是，这样一来，如果后端恢复了，我们怎么知道呢，此时需要使用我们的熔断设计了。这个在后面会说。

重试的代码比较简单也比较通用，完全可以不用侵入到业务代码中。这里有两个模式。一个是代码级的，像 Java 那样可以使用 Annotation 的方式（在 Spring 中你可以用到这样的注解），如果没有注解也可以包装在底层库或是 SDK 库中不需要让上层业务感知到。另外一种是走 Service Mesh 的方式（关于 Service Mesh 的方式，我会在后面的文章中介绍）。

### 重试的策略

Exponential Backoff 策略，就是"指数级退避"。在这种情况下，每一次重试所需要的休息时间都会成倍增加。这种机制主要是用来让被调用方能够有更多的时间来从容处理我们的请求。这其实和 TCP 的拥塞控制有点像。Spring 里面有个 spring-retry 项目。

```java
public enum Results {
    SUCCESS,
    NOT_READY,
    TOO_BUSY,
    NO_RESOURCE,
    SERVER_ERROR
}

// 定义一个 Exponential Backoff 的函数，其返回 2 的指数。
public static long getWaitTimeExp(int retryCount) {
    long waitTime = ((long) Math.pow(2, retryCount) );
    return waitTime;
}

// 在成功的情况下，以及不属于我们定义的错误下，我们是不需要重试的，而两次重试间需要等的时间是以指数上升的。
public static void doOperationAndWaitForResult() {
    // Do some asynchronous operation.
    long token = asyncOperation();

    int retries = 0;
    boolean retry = false;

    do {
        // Get the result of the asynchronous operation.
        Results result = getAsyncOperationResult(token);

        if (Results.SUCCESS == result) {
            retry = false;
        } else if ( (Results.NOT_READY == result) ||
                      (Results.TOO_BUSY == result) ||
                      (Results.NO_RESOURCE == result) ||
                      (Results.SERVER_ERROR == result) ) {
            retry = true;
        } else {
            retry = false;
        }
        if (retry) {
            long waitTime = Math.min(getWaitTimeExp(retries), MAX_WAIT_INTERVAL);
            // Wait for the next Retry.
            Thread.sleep(waitTime);
        }
    } while (retry && (retries++ < MAX_RETRIES));
}
```

# 熔断设计

熔断器模式像是那些容易导致错误的操作的一种代理，其能记录最近调用发生错误的次数，然后决定允许继续操作，或者立刻返回错误。熔断器模式减少了错误对系统性能的影响。

熔断器状态机： 1. 闭合状态，2. 断开状态，3. 半开状态

我们需要一个调用失败的计数器，如果调用失败，则使失败次数加 1。如果最近失败次数超过了给定时间内允许失败的阈值，则切换到断开状态。此时开启了一个超时时钟，当该时钟超过了该时间，则切换到半开状态。

- 在 closed 状态下，在特定时间内错误计数器会重置。
- 在断开状态下，对应用程序的请求会立刻返回错误响应。
- 在半开状态下，允许部分请求去调用服务。如果这些请求调用成功，那么可以认为之前的错误已经修正，此时切换到闭合，同时重置错误计数器。
- 如果一定数量的请求有调用失败的情况，则切回断开状态。
- 半开状态能够有效防止正在恢复中的服务被突然而来的大量请求再次拖垮。

[Hystrix](https://github.com/Netflix/Hystrix/wiki/How-it-Works#CircuitBreaker)

### 熔断设计的重点

- 错误的类型。不同类型的错误应该有不同的处理机制。
- 日志监控。熔断器应该能够记录所有失败的请求，以及一些可能会尝试成功的请求。
- 测试服务是否可用：在断开状态下，熔断器可以采用定期 ping 远程服务的健康检查接口来判断服务是否恢复。
- 手动重置：管理员应该要能够手动断开或者闭合熔断器。
- 并发问题：熔断器的实现不应该阻塞并发的请求或增加每次请求的负担。

# 降级设计

**降级设计本质是为了解决资源不足和访问量过大的问题。**

高速公路收费口在排队过长的情况下免费直接放行就是一种降级设计。一般来说，降级需要牺牲掉一些东西。

- 降低一致性。从强一致变成最终一致。一种是简化流程的一致性，一种是降低数据的一致性。
- 停止次要功能。比如暂停掉评论功能啥的。
- 简化功能，比如简化流程，只返回部分数据。

关于降低一致性举个例子，比如电商的下单交易系统，在强一致的情况下，需要结算账单，扣库存，扣余额，最后是发货流程。在系统降级时，我们可以把这一系列操作做成异步的，快速结算订单，不占库存，然后把在线支付降级成用户到付（省去支付环节），然后批量处理用户的订单，向用户发货，用户货到付款。

降低数据的一致性一般来说会使用缓存的方式，或者直接去掉数据。我们一般使用 cache aside 模式或者 read through 模式。应用程序先从 cache 取数据，取到则返回，如果没有得到，则从数据库中取数据并放入缓存。而更新数据时则先写数据库，成功后让缓存失效。Cache aside 是由调用方负责把数据加载到缓存中，而 Read through 则是用缓存服务自己来加载，对应用方是透明的。

### 降级设计的要点

- 需要清除定义好降级的关键条件。比如吞吐量大，响应时间过慢，失败次数过多，有网络或者服务故障等等。
- 需要梳理好业务，哪些是 must-have，哪些是 nice-to-have 的。
- 降级的时候需要牺牲掉一致性，或者一些业务流程。对于读请求，可以使用缓存；对于写请求，可以采用异步调用。并且需要做好对账准备。
- 降级的功能开关可以是一个系统的配置开关。做成配置时，你需要在要降级的时候推送相应的配置。比如网关限流时，在协议头中加入了一个限流程度的参数，让后端服务知道限流在发生中。当限流程度达到某个值时，系统开始自动降级。
- 降级需要演练。

# 限流设计

- 拒绝服务：统计当前哪个客户端的请求太多，直接拒绝掉这个客户端。
- 服务降级：停掉不重要的服务，或者只返回部分数据，或者返回缓存好的数据。
- 特权请求：先保大客户。
- 延时处理：队列缓冲。
- 弹性伸缩：自动化的发布、部署和服务注册的运维系统。

### 限流的实现方式

- 队列算法。可以做多个不同优先级的队列，分配不同比例的时间到不同的队列上。
- 漏斗算法（leaky bucket），一般用一个队列来实现。当请求过多时，队列就会积压，如果队列满了，就拒绝请求。
- 令牌桶算法，token bucket。在一个桶内按照一定速率放入一些 token，处理程序需要拿到 token 才能处理。

漏斗算法会以一个稳定的速度转发。而令牌桶算法则平时流量不大的时候在”攒钱“，流量大时可以一次发出队列中的请求，而后就收到令牌桶的控制。令牌桶可以做成一个第三方服务，在分布式系统中进行全局流量控制。

P99 和 P90 和蓄水池算法。

### 基于响应时间的动态限流。

上面的算法都是需要预先设定一个限流值，这要求每次发布服务时都做相应的性能测试，找到系统最大的性能值。但很多时候我们给不出一个合适的值。而且不同的 API 有不同的性能，我们要在线上为每一个 API 配置不同的限流值，很难配置和管理。而且服务是可以伸缩的，所以限流的值也应该自动伸缩。

我们想使用一种动态限流的方式，动态地感知系统的压力来自动化地限流。比如 TCP 的拥塞控制使用 Round Trip Time（RTT）来探测网络的延时和性能，从而设定相应的“滑动窗口”的大小，以让发送的速率和网络的性能相匹配。

我们记录下每次调用后端请求的响应时间，然后在一个时间区间内（比如，过去 10 秒）的请求计算一个响应时间的 P90 或 P99 值，也就是把过去 10 秒内的请求的响应时间排个序，然后看 90% 或 99% 的位置是多少。这样，我们就知道有多少请求大于某个响应时间。如果这个 P90 或 P99 超过我们设定的阈值，那么我们就自动限流。

### 限流的设计要点

- 限流应该是在架构的早期考虑。当架构形成后，限流不是很容易加入。
- 限流模块性能必须好，而且对流量的变化也是非常灵敏的，否则太过迟钝的限流，系统早因为过载而挂掉了。
- 限流应该有个手动的开关，这样在应急的时候，可以手动操作。
- 限流发生时，应有监控事件通知。这样，运维人员可以及时跟进。而且还可以自动化触发扩容或降级，以缓解系统压力。
- 限流发生时，对于拒掉的请求，应返回特定限流错误码，以和其它错误区分。客户端看到限流，可调整发送速度，或重试。
- 限流应该让后端的服务感知到。限流发生时，我们应该在协议头中塞进一个标识，比如 HTTP Header 中，放入一个限流的级别，告诉后端服务目前正在限流中。这样，后端服务可以根据这个标识决定是否做降级。

# 隔离设计（船舱分割）

**按服务种类来分离**：比如将服务分成用户、商品、社区三个版块。三个版块分别使用不同的域名、服务器和数据库，做到从接入层到应用层再到数据层完全隔离。

这种架构存在的问题：

- 如果我们需要同时获得多个版块的数据，那么就需要调用多个服务，这会降低性能。
- 如果有大数据平台，这增加了数据合并的复杂度。对此我们需要一个框架或者中间件。
- 如果我们的业务逻辑或是业务流程需要跨版块的话，一个版块的故障也会导致整个流程走不下去。
- 跨版块的交互也会变复杂。需要一个高可用、持久化的消息中间件来打通各个版块的数据。
- 还有分布式事务的问题存在。（2PC, TCC, 补偿，重试）

**按用户的请求来分离（多租户隔离）**：将用户分到不同的组，分别使用不同的服务实例。这样一来，一个服务实例挂了，只会影响到一部分的用户。对于一些比较大的客户，我们可以为他们设置专门的实例。

一般来说会采取比较折中的方案，服务是共享的，数据则通过分区来隔离。而对于一些特别重要的客户，则可以考虑服务也独立。

隔离设计的重点：

- 我们需要定义好隔离业务的大小和粒度，过大过小都不好。
- 需要考虑系统的复杂度，成本，性能，资源使用的问题，找到一个合适的均衡方案。
- 隔离模式需要配置一些高可用、重试、异步、消息中间件、流控、熔断等设计模式。
- 需要一个能非常完整的看到所有服务的监控系统，这点非常重要。
