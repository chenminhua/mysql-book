### innodb 的索引

B+树高扇出，高度平衡。数据库中，B+树的高度一般在 2 到 4 层，也就是说查找某一键值的行记录时最多只需要 2 到 4 次 IO。以 InnoDB 的一个整数字段索引为例，度差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。

主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。聚集索引的存储在逻辑上是连续的，但是在物理上并不是。叶子节点上存数据。在叶子节点这一层上添加额外的向前和向后的指针, 来优化扫描性能。辅助索引叶子节点并不包含行的全部数据，但是其存储了主键。

有时候即使可以使用辅助索引，优化器也会选择不用索引。因为顺序读要远远快于离散读。只有当使用辅助索引查找的数据量是少量的时，优化器才会选择使用辅助索引。

### 覆盖索引

在使用辅助索引的查询情况下，往往需要回表获取索引字段以外的数据。而覆盖索引可以用于避免回表查询。

**在一个市民信息表上，是否有必要将身份证号和名字建立联合索引？**我们知道，身份证号是市民的唯一标识。也就是说，如果有根据身份证号查询市民信息的需求，我们只要在身份证号字段上建立索引就够了。而再建立一个（身份证号、姓名）的联合索引，是不是浪费空间？如果现在有一个高频请求，要根据市民的身份证号查询他的姓名和年龄，这个联合索引就有意义了。**它可以在这个高频请求上用到覆盖索引，不再需要回表查整行记录，减少语句的执行时间。**

### 索引下推

现在有一个需求：检索出表中“名字第一个字是张，而且年龄是 10 岁的所有男孩”。那么，SQL 语句是这么写的：

    mysql> select * from tuser where name like '张%' and age=10 and ismale=1;

你已经知道了前缀索引规则，所以这个语句在搜索索引树的时候，只能用 “张”，找到第一个满足条件的记录 ID3。当然，这还不错，总比全表扫描要好。然后呢？当然是判断其他条件是否满足。

在 MySQL 5.6 之前，只能从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值。而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。

### 建议使用自增 id 做主键

1. 递增插入，都是追加操作，不用挪动其他记录，不涉及页分裂问题。
2. 二级索引的叶子节点存的是主键索引，主键长度越小，二级索引占用的空间也就越小。

### 用普通索引还是唯一索引

身份证号较大，不建议做主键，那么是创建唯一索引，还是普通索引？

##### 查询

假设，执行查询的语句是 select id from T where k=5。这个查询语句在索引树上查找的过程，先是通过 B+树从树根开始，按层搜索到叶子节点，然后数据页内部通过二分法来定位记录。

- 对于普通索引来说，查找到满足条件的第一个记录(5,500)后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。
- 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。

这两者的性能差距微乎其微。InnoDB 的数据是**按数据页为单位来读写**的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在 InnoDB 中，每个数据页的大小默认是 16KB。那么，对于普通索引来说，要多做的那一次“查找和判断下一条记录”的操作，就只需要一次指针寻找和一次计算。对于整型字段，一个数据页可以放近千个 key，所以基本读这个页就够了。

##### 更新

当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB 会将这些更新操作缓存在 **change buffer** 中。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。

将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 **purge**。除了访问这个数据页会触发 purge 外，系统有后台线程会定期 purge。在数据库正常关闭（shutdown）的过程中，也会执行 purge 操作。显然，如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。

但是对于唯一索引来说，其更新就不能使用 change buffer，因为要检查唯一性。

change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。

假设我们现在要插入一条数据，如果这个记录要更新的目标页现在在内存中，那么普通索引和唯一索引性能没有什么差别。但如果这个记录要更新的目标页不在内存中的话，对于普通索引来说，只要将更新记录在 change buffer，而对于唯一索引的情况，则需要将数据页从磁盘读入内存。change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。

因为 purge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 purge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。

因此，**对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好**。这种业务模型常见的就是账单类、日志类的系统。

反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 purge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。

综上，普通索引和唯一索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。建议尽量选择普通索引。如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。

特别地，在使用机械硬盘时，change buffer 这个机制的收效是非常显著的。所以，当你有一个类似“历史数据”的库，并且出于成本考虑用的是机械硬盘时，那你应该特别关注这些表里的索引，尽量使用普通索引，然后把 change buffer 尽量开大，以确保这个“历史数据”表的数据写入速度。

### change buffer 和 redo log

假设现在有一条 sql 要插入两条记录，分别在两个不同的数据页上。

1.  Page 1 在内存中，直接更新内存；
2.  Page 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 Page 2 插入一行”这个信息
3.  将上述两个动作记入 redo log 中。

做完上面这些，事务就可以完成了。所以，你会看到，执行这条更新语句的成本很低，就是写了两处内存，然后写了一处磁盘（两次操作合在一起写了一次磁盘），而且还是顺序写的。而至于将 change buffer 刷盘到磁盘共享表空间，以及将数据页刷到磁盘表空间都是后台操作，不影响更新的响应时间。

然后又执行一条读这两条数据的 sql。如果读语句发生在更新语句后不久，内存中的数据都还在，读 Page 1 的时候，直接从内存返回。要读 Page 2 的时候，需要把 Page 2 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果。可以看到，直到需要读 Page 2 的时候，这个数据页才会被读入内存。

所以，如果要简单地对比这两个机制在提升更新性能上的收益的话，**redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。**

注意 change buffer 一开始是写内存的，那么如果这个时候机器掉电重启，会不会导致 change buffer 丢失呢？其实不会。虽然是只更新内存，但在事务提交时，change buffer 的操作也记录到 redo log 里了，所以崩溃恢复的时候，change buffer 也能找回来。

### 优化器如何选择索引

在数据库里面，扫描行数是影响执行代价的因素之一（还有是否使用临时表、是否排序等因素）。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的 CPU 资源越少。那么，问题就是：**扫描行数是怎么判断的？**

MySQL 在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。这个统计信息就是索引的“区分度”。基数越大，索引的区分度越好。我们可以使用 show index 方法，看到一个索引的基数。索引的基数只是一个估计，未必准确。既然是统计信息不对，那就修正。**analyze table t** 命令，可以用来重新统计索引信息。我们来看一下执行效果。

所以在实践中，如果你发现 explain 的结果预估的 rows 值跟实际情况差距比较大，可以采用这个方法来处理。其实，如果只是索引统计不准确，通过 analyze 命令可以解决很多问题，但是前面我们说了，优化器可不止是看扫描行数。而对于其他优化器误判的情况，你可以在应用端用 force index 来强行指定索引，也可以通过修改语句来引导优化器，还可以通过增加或者删除索引来绕过这个问题。

### 前缀索引：怎么给字符串字段加索引？

如何在邮箱这样的字段上建立合理的索引?由于要使用邮箱登录，所以业务代码中一定会出现类似于这样的语句：

    mysql> select f1, f2 from SUser where email='xxx';

同时，MySQL 是支持前缀索引的，也就是说，你可以定义字符串的一部分作为索引。默认地，如果你创建索引的语句不指定前缀长度，那么索引就会包含整个字符串。比如，alter table SUser add index index2(email(6));这个索引里面，对每个记录都只取前 6 个字节。由于 email(6)这个索引结构中每个邮箱字段都只取前 6 个字节（即：zhangs），所以占用的空间会更小，这就是使用前缀索引的优势。损失是，可能会增加额外的记录扫描次数。

**使用前缀索引后，可能会导致查询语句读数据的次数变多,使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。**

于是，你就有个问题：当要给字符串创建前缀索引时，有什么方法能够确定我应该使用多长的前缀呢？实际上，我们在建立索引时关注的是区分度，区分度越高越好。因为区分度越高，意味着重复的键值越少。因此，我们可以通过统计索引上有多少个不同的值来判断要使用多长的前缀。比如我们要看一下 4~7 个字节的前缀索引，可以用这个语句：

    mysql> select
      count(distinct left(email,4)）as L4,
      count(distinct left(email,5)）as L5,
      count(distinct left(email,6)）as L6,
      count(distinct left(email,7)）as L7,
    from SUser;

需要注意的是使用前缀索引就用不上覆盖索引对查询性能的优化了，这也是你在选择是否使用前缀索引时需要考虑的一个因素。

对于类似于邮箱这样的字段来说，使用前缀索引的效果可能还不错。但是，遇到前缀的区分度不够好的情况时，我们要怎么办呢？通常有两种方法，**第一种方式是使用倒序存储，第二种方式是使用 hash 字段。**

假设你在维护一个学校的学生信息数据库，学生登录名的统一格式是”学号@gmail.com", 而学号的规则是：十五位的数字，其中前三位是所在城市编号、第四到第六位是学校编号、第七位到第十位是入学年份、最后五位是顺序编号。

系统登录的时候都需要学生输入登录名和密码，验证正确后才能继续使用系统。这个索引要怎么设计呢？

由于这个学号的规则，无论是正向还是反向的前缀索引，重复度都比较高。因为维护的只是一个学校的，因此前面 6 位（其中，前三位是所在城市编号、第四到第六位是学校编号）其实是固定的，邮箱后缀都是@gamil.com，因此可以只存入学年份加顺序编号，它们的长度是 9 位。

而其实在此基础上，可以用数字类型来存这 9 位数字。比如 201100001，这样只需要占 4 个字节。其实这个就是一种 hash，只是它用了最简单的转换规则：字符串转数字的规则，而刚好我们设定的这个背景，可以保证这个转换后结果的唯一性。

对索引字段用函数操作就可能会不走索引。

mysql 中字符串和数字作比较的时候，会把字符串转为数字。

如果两个表上面字符集不同，在进行两个表进行连接的时候，会导致用不上连接字段上的索引。原因是需要对连接字段做函数操作。

## select 查询长时间不返回怎么办

第一，再等 Mdl 锁。show processlist 看下是不是有人在持有 mdl 写锁。查看 sys.schema_table_lock_waits 表可以看到谁在持有 mdl 写锁。Kill 掉它就好了。

第二，等 flush。show processlist 看下是不是有 waiting for table flush，如果有的话，和可能是某个 flush 操作被堵住了。

第三，等行锁。查看 sys.innodb_lock_waits 表。

```
select * from t sys.innodb_lock_waits where locked_table = 't'\G
```
