hbase url shortener

列式数据库顺序地存储列值数据。其基于这样一种假设：对于特定的查询，不是所有的值都是必需的。

值得注意的是，hbase 并不是一个列式存储的数据库，但是其利用了磁盘上的列存储格式。传统的列式数据库比较适合实时存取数据的场景，而 hbase 比较适合键值对的数据存取，或者有序的数据存取。

举例来说，facebook 每天增量存储到它们 hadoop 集群的数据量超过 15TB。

facebook 还有一个实时组件，就是消息系统，其中包括聊天、涂鸦墙和电子邮件，每月会产生超过 1350 亿条数据。

bigtable 和 hbase 的典型使用场景是 webtable。行健是反转的 url，有若干个列族：contents, anchor, language

#### 表，行，列，cell

(table, RowKey, Family, Column, Timestamp) -> value

SortedMap<Rowkey, List<SortedMap<Column, List<Value, Timestamp>>>>

#### region

hbase 中扩展和负载均衡的基本单元。

本质上是以行健排序的连续存储区间。

如果 region 太大，系统会自动进行拆分，如果太小，则会自动进行合并。

一张表初始的时候只有一个 region，用户开始向表中插入数据时，系统会检查 region 大小，如果超过限制，则将其拆分为大小相似的两个 region。

每个 region 只能由一台 region 服务器加载，每个 region 服务器可以加载多个 region。

每个 region 服务器加载的 region 数量最佳为 10 - 1000。每个 region 大小最佳为 1G 到 2 G。

### api

提供了建表，删表，增加列族和删除列族操作。
提供了修改表和列族元数据的功能。
提供了对给定行健值进行增删查的功能。

scan api 提供了高效遍历某个范围行的功能。

支持单行事务。不支持跨行跨表的事务。

通过提供包装器集成了 mapReduce 框架。

## 组件

客户端库，一台主服务器，多台 region 服务器

## 实现

数据存储在 HFile 中，是经过排序的键值映射结构。文件内部由连续的块组成，块的索引信息存储在文件的尾部。

当把 HFile 打开并加载到内存中时，块的索引信息会被优先加载到内存中，每个块默认大小为 64kb，可以配置。

存储文件通常保存在 hdfs 中。hdfs 提供了一个可扩展的，持久的，冗余的 hbase 存储层。

每次更新数据时，都会先将数据记录在 commit log（WAL）中,然后才会写入内存的 memstore 中，一旦内存保存的写入数据累计到一定大小，系统会进行刷盘。数据移出内存并刷盘之后，系统会丢弃对应的提交日志。

在 flush 数据的过程中，不必阻塞系统的读写，通过滚动内存中的 memstore 就能达到这个目的。也就是将满的旧的 memstore 转换成文件，用新的 memstore 替换旧的。

因为**存储文件是不可改变的**，无法通过移除某个键值对来删除值，可以通过做个删除标记的方式来表明某行已经被删除。

LSM 树

合并： minor 合并和 major 合并

每台 region 服务器在 zk 中注册一个自己的临时节点，主服务器会利用临时节点来发现可用服务器，还可以利用临时节点来跟踪机器故障和网络分区。
