发布订阅的对象是主题 （Topic）。发布消息（Record）的是生产者（producer），订阅主题消息的是消费者（consumer），生产者和消费者都是客户端（clients）。

kafka 服务端由 broker 服务进程组成。broker 负责接收并处理请求，并对消息进行持久化。broker 通常分布在不同机器上，以实现高可用（HA）。

### 备份与高可用

实现高可用的另一种手段是备份（Replication），就是把同一份数据拷贝到多台机器上。这些相同的数据拷贝称为副本（Replica）。

副本数量是可配置的，分为 leader 和 follower。Producer 发来的消息总是写到 Leader replica,而 Consumer 总是从 Leader replica 读消息；Follower Replica 则是备胎，只是向 leader replica 发送请求，让 Leader 把最新消息发给它，来实现同步。

为什么 Kafka 不像 MySQL 那样允许 follower 对外提供读服务？因为 kafka 的 leader 副本已经均匀分布在不同机器上，已经起到了负载均衡的作用。

### 分区与伸缩性（Scalability）。

如果数据量太大，导致领导者积累太多数据以至于单台 broker 无法容纳了，咋办？这时候就需要分区（partitioning）。（在其他系统里面有时候被称为 sharding, region）。

Kafka 的分区机制是指将每个 Topic 分成多个分区，每个消息只会被发送到一个分区。Kafka 的分区编号是从 0 开始的，如果某个 Topic 有 100 个分区，那么它们的分区号就是 0 到 99。

副本是在分区这个层级上定义的。每条消息在分区中的位置信息由一个 Offset 来表征。

### 三层消息架构：

- 主题层，每个主题可以配置 M 个分区，每个分区可以有 N 个副本。
- 分区层，每个分区有 1 个 Leader 副本和 N-1 个 Follower 副本。follower 副本只做数据冗余。
- 消息层，分区中包含若干消息，每条消息的位移从 0 开始。

### Kafka Broker 是如何持久化数据的？

Kafka 使用消息日志（Log）来保存数据。一个日志就是磁盘上一个 Append-only 的文件（顺序写）。

Kafka 通过日志段（Log segment）机制来实现日志删除。在 Kafka 底层，一个日志被分成多个日志段，消息被追加到当前最新的 log segment 中。当一个 Log segment 被写满后，kafka 会自动切分出一个新的日志段，并将老的日志段封存起来。kafka 会定期检查老的 log segment 是否能被删除，从而实现磁盘空间回收的目的。

### Consumer Group

主要是为了提升消费端的吞吐，多个消费者同时消费。

假设组内某个实例挂掉了，Kafka 能自动检测到并把这个 Failed 实例之前负责的分区转移给其他活着的消费者。这就是 Kafka 中大名鼎鼎的“重平衡”（Rebalance）。嗯，其实既是大名鼎鼎，也是臭名昭著，因为由重平衡引发的消费者问题比比皆是。事实上，目前很多重平衡的 Bug 社区都无力解决。

每个消费者在消费消息的过程中必然需要有个字段记录它当前消费到了分区的哪个位置上，这个字段就是消费者位移（Consumer Offset）。注意，这和上面所说的位移完全不是一个概念。上面的“位移”表征的是分区内的消息位置，它是不变的，即一旦消息被成功写入到一个分区上，它的位移值就是固定的了。而消费者位移则不同，它可能是随时变化的，毕竟它是消费者消费进度的指示器嘛。另外每个消费者有着自己的消费者位移，因此一定要区分这两类位移的区别。我个人把消息在分区中的位移称为分区位移，而把消费者端的位移称为消费者位移。

### 生态

kafka 不单是一个消息引擎系统，而且是能够实现 Exactly-Once 处理语义的实时流处理平台。
你可能听说过 Apache Storm、Apache Spark Streaming 亦或是 Apache Flink，它们在大规模流处理领域可都是响当当的名字。令人高兴的是，Kafka 经过这么长时间不断的迭代，现在已经能够稍稍比肩这些框架了。我在这里使用了“稍稍”这个字眼，一方面想表达 Kafka 社区对于这些框架心存敬意；另一方面也想表达目前国内鲜有大厂将 Kafka 用于流处理的尴尬境地，毕竟 Kafka 是从消息引擎“半路出家”转型成流处理平台的，它在流处理方面的表现还需要经过时间的检验。
如果我们把视角从流处理平台扩展到流处理生态圈，Kafka 更是还有很长的路要走。前面我提到过 Kafka Streams 组件，正是它提供了 Kafka 实时处理流数据的能力。但是其实还有一个重要的组件我没有提及，那就是 Kafka Connect。
我们在评估流处理平台的时候，框架本身的性能、所提供操作算子（Operator）的丰富程度固然是重要的评判指标，但框架与上下游交互的能力也是非常重要的。能够与之进行数据传输的外部系统越多，围绕它打造的生态圈就越牢固，因而也就有更多的人愿意去使用它，从而形成正向反馈，不断地促进该生态圈的发展。就 Kafka 而言，Kafka Connect 通过一个个具体的连接器（Connector），串联起上下游的外部系统。
整个 Kafka 生态圈如下图所示。值得注意的是，这张图中的外部系统只是 Kafka Connect 组件支持的一部分而已。目前还有一个可喜的趋势是使用 Kafka Connect 组件的用户越来越多，相信在未来会有越来越多的人开发自己的连接器。
