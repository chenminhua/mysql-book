# 部署环境

- 在 Linux 部署 Kafka 能够享受到零拷贝技术所带来的快速数据传输特性。
- 使用普通磁盘组成存储空间即可。使用机械磁盘完全能够胜任 Kafka 线上环境。
- 需要规划磁盘容量，预留足够空间

单位时间新增消息数，消息留存时间，消息平均大小，备份数，是否启用压缩。假设你的业务每天要往 kafka 集群发送 1 亿条消息，每条消息两个副本。消息默认保存两周，平均每条消息占用磁盘 1KB。估算一下总的空间大小是 200GB 每天。如果预留 10%的空间给消息之外的其他数据，则是 220G 每天。乘以 14，在乘以 0.75 的压缩比（假设），大概需要 2.25TB。

对于 kafka 这种通过网络进行大量数据传输的框架而言，带宽很容易成为瓶颈。带宽不足导致的性能问题占一半以上。以 1Gbps 的千兆网络为例，假设你现在的业务目标是在 1 小时内处理 1TB 的业务数据，请问你需要多少台 kafka 服务器？

由于带宽是 1Gbps，即每秒处理 1G 数据，假设 kafka 能用到 70%的带宽资源，也就是 700Mbps。
你还不能让 kafka 常规性地使用这么大带宽，通常只有三分之一，大约 240Mbps。
这样，我们大概可以算出一小时处理 1TB 数据需要 10 台 kafka。
如果你希望数据一共有三个副本，则是 30 台。

## 关键配置

这些配置并不单指 Broker 端参数，也有主题级别的参数、JVM 参数和操作系统级别的参数。需要你注意的是，这里所说的 Broker 端参数也被称为静态参数（Static Configs）。我会在专栏后面介绍与静态参数相对应的动态参数。所谓静态参数，是指你必须在 Kafka 的配置文件 server.properties 中进行设置的参数，不管你是新增、修改还是删除。同时，你必须重启 Broker 进程才能令它们生效。而主题级别参数的设置则有所不同，Kafka 提供了专门的 kafka-configs 命令来修改它们。至于 JVM 和操作系统级别参数，它们的设置方法比较通用化，我介绍的也都是标准的配置参数，因此，你应该很容易就能够对它们进行设置。

Broker 端参数目前 Kafka Broker 提供了近 200 个参数。

#### Broker 存储相关

首先 Broker 是需要配置存储信息的，即 Broker 使用哪些磁盘。那么针对存储信息的重要参数有以下这么几个：

- log.dirs：这是非常重要的参数，指定了 Broker 需要使用的若干个文件目录路径。
- log.dir：注意这是 dir，结尾没有 s，说明它只能表示单个路径，它是补充上一个参数用的。

这两个参数应该怎么设置呢？很简单，你只要设置 log.dirs，即第一个参数就好了，不要设置 log.dir。而且更重要的是，在线上生产环境中一定要为 log.dirs 配置多个路径，具体格式是一个 CSV 格式，也就是用逗号分隔的多个路径，比如/home/kafka1,/home/kafka2,/home/kafka3 这样。如果有条件的话你最好保证这些目录挂载到不同的物理磁盘上。

#### zk 相关

Kafka 与 ZooKeeper 相关的最重要的参数当属 zookeeper.connect。这也是一个 CSV 格式的参数，比如我可以指定它的值为 zk1:2181,zk2:2181,zk3:2181。2181 是 ZooKeeper 的默认端口。

如果你有两套 Kafka 集群，假设分别叫它们 kafka1 和 kafka2，那么两套集群的 zookeeper.connect 参数可以这样指定：zk1:2181,zk2:2181,zk3:2181/kafka1 和 zk1:2181,zk2:2181,zk3:2181/kafka2。切记 chroot 只需要写一次，而且是加到最后的。

#### broker 连接相关

- listeners：监听器，告诉外部连接者要通过什么协议访问指定主机名和端口开放的 Kafka 服务。
- advertised.listeners：Advertised 的含义表示宣称的、公布的，就是说这组监听器是 Broker 用于对外发布的。
- host.name/port：过期参数了，压根不要为它们指定值。

经常有人会问主机名这个设置中我到底使用 IP 地址还是主机名。这里我给出统一的建议：最好全部使用主机名，即 Broker 端和 Client 端应用配置中全部填写主机名。 Broker 源代码中也使用的是主机名，如果你在某些地方使用了 IP 地址进行连接，可能会发生无法连接的问题。

#### topic 管理

- auto.create.topics.enable：是否允许自动创建 Topic。最好是 false。
- unclean.leader.election.enable：是否允许 Unclean Leader 选举。最好是 false。
- auto.leader.rebalance.enable：是否允许定期进行 Leader 选举。最好是 false。

#### 数据留存方面

- log.retention.{hours|minutes|ms}：这是个“三兄弟”，都是控制一条消息数据被保存多长时间。通常情况下我们还是设置 hours 级别的多一些，比如 log.retention.hours=168 表示默认保存 7 天的数据，自动删除 7 天前的数据。
- log.retention.bytes：这是指定 Broker 为消息保存的总磁盘容量大小。这个值默认是 -1，表明不设限。
- message.max.bytes：控制 Broker 能够接收的最大消息大小。默认的 1000012 太少了，还不到 1MB。

#### topic 级别参数

- retention.ms：规定了该 Topic 消息被保存的时长。默认是 7 天，即该 Topic 只保存最近 7 天的消息。一旦设置了这个值，它会覆盖掉 Broker 端的全局参数值。
- retention.bytes：规定了要为该 Topic 预留多大的磁盘空间。和全局参数作用相似，这个值通常在多租户的 Kafka 集群中会有用武之地。当前默认值是 -1，表示可以无限使用磁盘空间。

```sh
# 创建topic
bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic transaction --partitions 1 --replication-factor 1 --config retention.ms=15552000000 --config max.message.bytes=5242880

# 修改topic设置
bin/kafka-configs.sh --zookeeper localhost:2181 --entity-type topics --entity-name transaction --alter --add-config max.message.bytes=10485760
```

#### JVM 参数

如果 Broker 所在机器的 CPU 资源非常充裕，建议使用 CMS 收集器。启用方法是指定-XX:+UseCurrentMarkSweepGC。否则，使用吞吐量收集器。开启方法是指定-XX:+UseParallelGC。

**如果你已经在使用 Java 8 了，那么就用默认的 G1 收集器就好了**。在没有任何调优的情况下，G1 表现得要比 CMS 出色，主要体现在更少的 Full GC，需要调整的参数更少等，所以使用 G1 就好了。设置方法很简单，你只需要设置下面这两个环境变量即可：KAFKA_HEAP_OPTS：指定堆大小。KAFKA_JVM_PERFORMANCE_OPTS：指定 GC 参数。、

```sh
$> export KAFKA_HEAP_OPTS=--Xms6g  --Xmx6g
$> export KAFKA_JVM_PERFORMANCE_OPTS= -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true
$> bin/kafka-server-start.sh config/server.properties
```

一个无脑通用的建议：将 JVM 堆设置成 6GB，这是目前业界比较公认的一个合理值。默认的 1GB 有点太小。毕竟 Kafka Broker 在与客户端进行交互时会在 JVM 堆上创建大量的 ByteBuffer 实例，Heap Size 不能太小。

#### 操作系统参数

- 首先是 ulimit -n。文件描述符系统资源并不像我们想象的那样昂贵，你不用太担心调大此值会有什么不利的影响。通常情况下将它设置成一个超大的值是合理的做法，比如 ulimit -n 1000000。
- 文件系统类型的选择。这里所说的文件系统指的是如 ext3、ext4 或 XFS 这样的日志型文件系统。根据官网的测试报告，XFS 的性能要强于 ext4，所以生产环境最好还是使用 XFS。
- 第三是 swap 的调优。网上很多文章都提到设置其为 0，将 swap 完全禁掉以防止 Kafka 进程使用 swap 空间。我个人建议将 swappniess 配置成一个接近 0 但不为 0 的值，比如 1。
- 最后是提交时间或者说是 Flush 落盘时间。向 Kafka 发送数据并不是真要等数据被写入磁盘才会认为成功，而是只要数据被写入到操作系统的页缓存（Page Cache）上就可以了，随后操作系统根据 LRU 算法会定期将页缓存上的“脏”数据落盘到物理磁盘上。这个定期就是由提交时间来确定的，默认是 5 秒。一般情况下我们会认为这个时间太频繁了，可以适当地增加提交间隔来降低物理磁盘的写操作。当然你可能会有这样的疑问：如果在页缓存中的数据在写入到磁盘前机器宕机了，那岂不是数据就丢失了。的确，这种情况数据确实就丢失了，但鉴于 Kafka 在软件层面已经提供了多副本的冗余机制，因此这里稍微拉大提交间隔去换取性能还是一个合理的做法。

# 无消息丢失配置

首先要明确，在 Kafka 的世界里什么才算是消息丢失，或者说 Kafka 在什么情况下能保证消息不丢失。这点非常关键，因为很多时候我们容易混淆责任的边界，如果搞不清楚事情由谁负责，自然也就不知道由谁来出解决方案了。一句话概括，**Kafka 只对“已提交”的消息（committed message）做有限度的持久化保证.**

- 什么是已提交的消息？当 Kafka 的若干个 Broker 成功地接收到一条消息并写入到日志文件后，它们会告诉生产者程序这条消息已成功提交。此时，这条消息在 Kafka 看来就正式变为“已提交”消息了。那为什么是若干个 Broker 呢？这取决于你对“已提交”的定义。你可以选择只要有一个 Broker 成功保存该消息就算是已提交，也可以是令所有 Broker 都成功保存该消息才算是已提交。不论哪种情况，Kafka 只对已提交的消息做持久化保证这件事情是不变的。

## 消息丢失案例

案例 1：Producer 程序丢失消息。

这应该算是被抱怨最多的数据丢失场景了。Producer 是异步发送消息的，调用 producer.send(msg) 这个 API 是 fire and forget 的，通常会立即返回，但不能认为消息发送已完成。现在有不少公司是用这个 api 发消息的，这可能导致消息压根没有发送到 broker 或者别 broker 拒绝，但是发送端根本不知道。

解决此问题的方法非常简单：**使用 producer.send(msg, callback)，不要使用 producer.send(msg)**。一旦出现消息提交失败的情况，你就可以有针对性地进行处理。

举例来说，如果是因为那些瞬时错误，那么仅仅让 Producer 重试就可以了；如果是消息不合格造成的，那么可以调整消息格式后再次发送。总之，处理发送失败的责任在 Producer 端而非 Broker 端。你可能会问，发送失败真的没可能是由 Broker 端的问题造成的吗？当然可能！如果你所有的 Broker 都宕机了，那么无论 Producer 端怎么重试都会失败的，此时你要做的是赶快处理 Broker 端的问题。但之前说的核心论据在这里依然是成立的：Kafka 依然不认为这条消息属于已提交消息，故对它不做任何持久化保证。

案例 2 ：Consumer 程序丢失数据。

解决办法很简单：**先消费消息，再更新位移**。这种方式带来的问题是消息的重复处理。

还存在一个问题是，Consumer 程序获取到消息后开启多个线程异步处理消息，而 Consumer 程序自动地向前更新位移。假如其中某个线程运行失败了，它负责的消息没有被成功处理，但位移已经被更新了，因此这条消息对于 Consumer 而言实际上是丢失了。这里的关键在于 Consumer 自动提交位移，与你没有确认书籍内容被全部读完就将书归还类似，你没有真正地确认消息是否真的被消费就“盲目”地更新了位移。

这个问题的解决方案也很简单：如果是多线程异步处理消费消息，Consumer 程序不要开启自动提交位移，而是要应用程序手动提交位移。**单个 Consumer 程序使用多线程来消费消息说起来容易，写成代码却异常困难，因为你很难正确地处理位移的更新，也就是说避免无消费消息丢失很简单，但极易出现消息被消费了多次的情况**。

### 最佳实践

- 使用 producer.send(msg, callback)。要有回调。
- 设置 acks = all。生产者参数。表明所有副本 Broker 都要接收到消息，该消息才算是“已提交”。
- 设置 retries（生产者参数）为一个较大的值。当出现网络的瞬时抖动时，自动重试发送消息。
- 设置 unclean.leader.election.enable = false。（Broker 参数，不让不干净的节点参加竞选）
- 设置 replication.factor >= 3。Broker 端的参数。消息多保存几份。
- 设置 min.insync.replicas > 1。Broker 端参数，消息至少要被写入到多少个副本才算是“已提交”。
- replication.factor > min.insync.replicas。推荐 replication.factor = min.insync.replicas + 1。
- 消费者端 enable.auto.commit = false，手动提交位移。
